# NLP
![NLP](NLP.png?raw=true "Title")

# Задача

Построить модель классификации для поиска токсичных комментариев пользователей. Поиск токсичных комментарив необходим, чтобы в дальнейшем автоматически отправлять их на модерацию. 
В качестве оценки качества модели была выбрана `F1`, значение которой должно быть не меньше 0.75. 

# Содержание
1  Подготовка

1.1  EDA

1.1.1  Баланс классов

1.1.2  Длина знаков и слов в классах

1.1.3  Встречаемость слов в в классах

1.2  Подготовка данных к обучению модели

1.3  Вывод

2  Обучение

2.1  Logistic Regression

2.2  Random Forest

2.3  CatBoost

2.4  Вывод

2.5  Тестирование модели

3  Выводы


**Описание данных**

В наличие были данные с разметкой на позитивные и негативные сообщения.

Колонка `text` содержит текст комментария, а `toxic` — разметку.

# Используемые библиотеки
* os
* pandas
* numpy
* matplotlib и seaborn
* wordcloud
* re
* nltk
* collections
* torch
* transformers
* tqdm
* sklearn
* catboost
