# NLP
![NLP](NLP.png?raw=true "Title")

# Задача

Построить модель классификации для поиска токсичных комментариев пользователей. Поиск токсичных комментарив необходим, чтобы в дальнейшем автоматически отправлять их на модерацию. 
В качестве оценки качества модели была выбрана `F1`, значение которой должно быть не меньше 0.75. 

# Содержание
1. Подготовка
    1. EDA
          1. Баланс классов
          2. Длина знаков и слов в классах
          3. Встречаемость слов в в классах
    2.  Подготовка данных к обучению модели
    3.  Вывод
    
2. Обучение
    1. Logistic Regression
    2. Random Forest
    3. CatBoost
    4. Вывод


3. Тестирование модели

4. Выводы


**Описание данных**

В наличие были данные с разметкой на позитивные и негативные сообщения.

Колонка `text` содержит текст комментария, а `toxic` — разметку.

# Используемые библиотеки
* os
* pandas
* numpy
* matplotlib и seaborn
* wordcloud
* re
* nltk
* collections
* torch
* transformers
* tqdm
* sklearn
* catboost
